import json
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    mean_absolute_error,
    mean_squared_error,
)

import plotly.express as px
from math import sqrt


# ============================================================================
# 1. ë°ì´í„° ë¡œë“œ: ais_results í´ë” ë‚´ aisResult*.json â†’ DataFrame
# ============================================================================

def load_all_ais_results(folder: str = "./ais_results") -> pd.DataFrame:
    folder_path = Path(folder)
    rows = []

    json_files = sorted(folder_path.glob("aisResult*.json"))
    print(f"[INFO] ì´ {len(json_files)}ê°œ JSON íŒŒì¼ ë°œê²¬")

    for file in json_files:
        try:
            data = json.loads(file.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"[WARN] JSON íŒŒì‹± ì‹¤íŒ¨: {file.name} / {e}")
            continue

        mmsi = data.get("mmsi")
        pred_list = data.get("PredResult", [])

        if not mmsi or not isinstance(pred_list, list) or len(pred_list) == 0:
            print(f"[WARN] mmsi ë˜ëŠ” PredResult ì´ìƒ: {file.name}")
            continue

        for item in pred_list:
            rows.append({
                "mmsi": str(mmsi),
                "seq": item.get("SEQ"),
                "before_lat": item.get("BEFORE_LAT"),
                "before_lon": item.get("BEFORE_LON"),
                "after_lat": item.get("AFTER_LAT"),
                "after_lon": item.get("AFTER_LON"),
                "sog": item.get("SOG"),
                "moving_time": item.get("MOVINGTIME"),
                "arrival_time": item.get("ARRIVALTIME"),
            })

    df = pd.DataFrame(rows)
    print(f"[INFO] ë¡œë“œ ì™„ë£Œ: {df.shape[0]} rows, {df.shape[1]} columns")
    return df


# ============================================================================
# 2. Feature Engineering: ê±°ë¦¬ ê³„ì‚°(Haversine), MMSI ë‹¨ìœ„ ì§‘ê³„ ë“±
# ============================================================================

def haversine(lat1, lon1, lat2, lon2):
    """
    ìœ„ê²½ë„ ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ km ë‹¨ìœ„ë¡œ ê³„ì‚° (Haversine ê³µì‹)
    """
    R = 6371.0  # ì§€êµ¬ ë°˜ê²½ (km)
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1

    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2
    c = 2 * np.arcsin(np.sqrt(a))
    return R * c


def add_distance_feature(df: pd.DataFrame) -> pd.DataFrame:
    """
    BEFORE_LAT/LON ~ AFTER_LAT/LON ì‚¬ì´ì˜ ì´ë™ ê±°ë¦¬(km)ë¥¼ distance_km ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
    """
    df = df.copy()

    df["distance_km"] = haversine(
        df["before_lat"].astype(float),
        df["before_lon"].astype(float),
        df["after_lat"].astype(float),
        df["after_lon"].astype(float),
    )

    return df


def build_mmsi_level_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    MMSIë³„ë¡œ Featureë¥¼ ì§‘ê³„:
      - total_distance: ì „ì²´ ì´ë™ ê±°ë¦¬ í•©(km)
      - total_time: ì „ì²´ MOVINGTIME í•©(ì´ˆ)
      - mean_sog, std_sog, max_sog
      - dwell_hours: total_time(ì´ˆ) -> ì‹œê°„ ë‹¨ìœ„
    """
    agg = df.groupby("mmsi").agg({
        "distance_km": "sum",
        "moving_time": "sum",
        "sog": ["mean", "std", "max"],
    }).reset_index()

    agg.columns = [
        "mmsi",
        "total_distance",
        "total_time",
        "mean_sog",
        "std_sog",
        "max_sog",
    ]

    agg["dwell_hours"] = agg["total_time"] / 3600.0
    return agg


# ============================================================================
# 3. Clustering: ì„ ë°• ë™ì‘ íŒ¨í„´ K-Means í´ëŸ¬ìŠ¤í„°ë§
# ============================================================================

def run_clustering(feat_df: pd.DataFrame, n_clusters: int = 4):
    """
    K-Means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰í•˜ê³  cluster ë ˆì´ë¸” ë°˜í™˜
    """
    features = ["total_distance", "mean_sog", "std_sog", "max_sog", "dwell_hours"]

    X = feat_df[features].fillna(0.0)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init="auto")
    clusters = kmeans.fit_predict(X_scaled)

    feat_df = feat_df.copy()
    feat_df["cluster"] = clusters

    print("[INFO] K-Means í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ")
    return feat_df, kmeans, scaler


# ============================================================================
# 4. Classification: ì„ ë°• í´ëŸ¬ìŠ¤í„° ìœ í˜• ì˜ˆì¸¡ (Logistic vs RandomForest)
# ============================================================================

def run_cluster_classification(feat_df: pd.DataFrame):
    """
    K-Meansë¡œ ì–»ì€ clusterë¥¼ íƒ€ê²Ÿìœ¼ë¡œ Classification ìˆ˜í–‰
    LogisticRegression vs RandomForestClassifier ë¹„êµ
    """
    features = ["total_distance", "mean_sog", "std_sog", "max_sog", "dwell_hours"]
    X = feat_df[features].fillna(0.0)
    y = feat_df["cluster"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Logistic Regression
    log_clf = LogisticRegression(max_iter=1000, multi_class="auto")
    log_clf.fit(X_train, y_train)
    pred_log = log_clf.predict(X_test)

    # RandomForest Classifier
    rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)
    rf_clf.fit(X_train, y_train)
    pred_rf = rf_clf.predict(X_test)

    print("\n[Classification: Cluster ì˜ˆì¸¡]")
    print("  Logistic Accuracy:", accuracy_score(y_test, pred_log))
    print("  RandomForest Accuracy:", accuracy_score(y_test, pred_rf))
    print("  Logistic F1 (macro):", f1_score(y_test, pred_log, average="macro"))
    print("  RandomForest F1 (macro):", f1_score(y_test, pred_rf, average="macro"))

    return {
        "log_clf": log_clf,
        "rf_clf": rf_clf,
        "X_test": X_test,
        "y_test": y_test,
        "pred_log": pred_log,
        "pred_rf": pred_rf,
    }


# ============================================================================
# 5. Regression: ì²´ë¥˜ì‹œê°„(dwell_hours) ì˜ˆì¸¡ (Linear vs RandomForestRegressor)
# ============================================================================

def run_dwell_regression(feat_df: pd.DataFrame):
    """
    dwell_hours(ì„ ë°• ì²´ë¥˜ì‹œê°„)ì„ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ ëª¨ë¸
    - Linear Regression
    - RandomForest Regressor
    - RMSEë¥¼ sqrt(MSE) ë¡œ ì§ì ‘ ê³„ì‚°í•˜ì—¬ sklearn ë²„ì „ í˜¸í™˜ ë¬¸ì œ ë°©ì§€
    """

    features = ["total_distance", "mean_sog", "std_sog", "max_sog"]
    X = feat_df[features].fillna(0.0)
    y = feat_df["dwell_hours"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # ëª¨ë¸ ì„ ì–¸
    lr = LinearRegression()
    rf = RandomForestRegressor(n_estimators=200, random_state=42)

    # ëª¨ë¸ í•™ìŠµ
    lr.fit(X_train, y_train)
    rf.fit(X_train, y_train)

    # ì˜ˆì¸¡
    pred_lr = lr.predict(X_test)
    pred_rf = rf.predict(X_test)

    # ===========================
    # ğŸ”¥ sklearn êµ¬ë²„ì „ ëŒ€ì‘ RMSE ê³„ì‚°
    # ===========================
    mse_lr = mean_squared_error(y_test, pred_lr)
    mse_rf = mean_squared_error(y_test, pred_rf)

    rmse_lr = sqrt(mse_lr)
    rmse_rf = sqrt(mse_rf)

    mae_lr = mean_absolute_error(y_test, pred_lr)
    mae_rf = mean_absolute_error(y_test, pred_rf)

    print("\n[Regression: Dwell Hours ì˜ˆì¸¡]")
    print(f"  LinearRegression RMSE : {rmse_lr:.4f}, MAE: {mae_lr:.4f}")
    print(f"  RandomForest RMSE     : {rmse_rf:.4f}, MAE: {mae_rf:.4f}")

    return {
        "lr": lr,
        "rf": rf,
        "X_test": X_test,
        "y_test": y_test,
        "pred_lr": pred_lr,
        "pred_rf": pred_rf,
        "rmse_lr": rmse_lr,
        "rmse_rf": rmse_rf
    }

# ============================================================================
# 6. í˜¼ì¡ë„(congestion) ë¼ë²¨ ìƒì„± + Classification
# ============================================================================

def run_congestion_classification(feat_df: pd.DataFrame):
    """
    dwell_hoursê°€ ìƒìœ„ 25% ì´ìƒì´ë©´ 1(í˜¼ì¡), ì•„ë‹ˆë©´ 0(ë¹„í˜¼ì¡)ìœ¼ë¡œ ë¼ë²¨ë§
    """
    feat_df = feat_df.copy()
    thr = feat_df["dwell_hours"].quantile(0.75)
    feat_df["congestion"] = (feat_df["dwell_hours"] >= thr).astype(int)

    features = ["total_distance", "mean_sog", "std_sog", "max_sog"]
    X = feat_df[features].fillna(0.0)
    y = feat_df["congestion"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)
    rf_clf.fit(X_train, y_train)
    pred = rf_clf.predict(X_test)

    print("\n[Classification: í•­ë§Œ í˜¼ì¡ë„ ì˜ˆì¸¡]")
    print("  Accuracy:", accuracy_score(y_test, pred))
    print("  F1:", f1_score(y_test, pred))

    return {
        "rf_clf": rf_clf,
        "X_test": X_test,
        "y_test": y_test,
        "pred": pred,
        "threshold": thr,
    }


# ============================================================================
# 7. Plotly ì‹œê°í™”
# ============================================================================

def visualize_clusters(feat_df: pd.DataFrame):
    """
    mean_sog vs total_distance ë¥¼ í´ëŸ¬ìŠ¤í„° ìƒ‰ìœ¼ë¡œ ì‹œê°í™”
    """
    fig = px.scatter(
        feat_df,
        x="mean_sog",
        y="total_distance",
        color="cluster",
        hover_data=["mmsi", "dwell_hours"],
        title="ì„ ë°• ë™ì‘ íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼",
    )
    fig.show()


def visualize_dwell_distribution(feat_df: pd.DataFrame):
    """
    dwell_hours ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    """
    fig = px.histogram(
        feat_df,
        x="dwell_hours",
        nbins=30,
        title="ì„ ë°• ì²´ë¥˜ì‹œê°„(dwell_hours) ë¶„í¬",
    )
    fig.show()


# ============================================================================
# 8. ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ============================================================================

def main():
    # 1) ë°ì´í„° ë¡œë“œ
    df = load_all_ais_results("./ais_results")

    # 2) ê±°ë¦¬ Feature ì¶”ê°€
    df = add_distance_feature(df)

    # 3) MMSI ë ˆë²¨ Feature DataFrame ìƒì„±
    feat_df = build_mmsi_level_features(df)

    print("\n[INFO] MMSI ë ˆë²¨ Feature DataFrame Preview:")
    print(feat_df.head())

    # 4) í´ëŸ¬ìŠ¤í„°ë§
    feat_df, kmeans_model, scaler = run_clustering(feat_df, n_clusters=4)

    # 5) í´ëŸ¬ìŠ¤í„° Classification
    cls_result = run_cluster_classification(feat_df)

    # 6) Dwell Hours Regression
    reg_result = run_dwell_regression(feat_df)

    # 7) í˜¼ì¡ë„ Classification
    cong_result = run_congestion_classification(feat_df)

    # 8) ì‹œê°í™”
    visualize_clusters(feat_df)
    visualize_dwell_distribution(feat_df)

    print("\n[INFO] ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")


if __name__ == "__main__":
    main()
